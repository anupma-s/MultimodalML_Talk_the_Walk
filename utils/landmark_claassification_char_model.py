# -*- coding: utf-8 -*-
"""Landmark_claassification_char_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fWY-jnD6GHJwsYeq5hIFUlu9DMrC462a
"""

import keras
import numpy as np

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

cd Colab\ Notebooks

cd drive/'My Drive'

data=np.load('data.npz')

labels=data['labels']

image_features=data['image_features']
text_features=data['text_features']
print(image_features.shape)
print(text_features.shape)
total_features=np.hstack((image_features,text_features))
print(total_features.shape)

#Image Features only
import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

 
# define baseline model
def baseline_model():
    # create model
    model = Sequential()
    model.add(Dense(4000, input_dim=2048*8, activation='relu'))
    model.add(Dense(1250,activation='relu'))
    model.add(Dense(750,activation='relu'))
    model.add(Dense(250,activation='relu'))
    model.add(Dense(10, activation='softmax'))
    # Compile model
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.summary()
    return model
 
estimator = KerasClassifier(build_fn=baseline_model, epochs=3, batch_size=5, verbose=1)
kfold = KFold(n_splits=10, shuffle=True)
results = cross_val_score(estimator,image_features, labels, cv=kfold)
print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

#Text Features only
import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

 
# define baseline model
def baseline_model():
    # create model
    model = Sequential()
    model.add(Dense(2500, input_dim=5580, activation='relu'))
    model.add(Dense(1250,activation='relu'))
    model.add(Dense(750,activation='relu'))
    model.add(Dense(250,activation='relu'))
    model.add(Dense(10, activation='softmax'))
    # Compile model
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.summary()
    return model
 
estimator = KerasClassifier(build_fn=baseline_model, epochs=3, batch_size=5, verbose=1)
kfold = KFold(n_splits=10, shuffle=True)
results = cross_val_score(estimator,text_features, labels, cv=kfold)
print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

#Text+Image Features 
import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

 
# define baseline model
def baseline_model():
    # create model
    model = Sequential()
    model.add(Dense(4250, input_dim=(5580+2048*8),activation='relu'))
    model.add(Dense(2250,activation='relu'))
    model.add(Dense(1250,activation='relu'))
    model.add(Dense(10, activation='softmax'))
    # Compile model
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.summary()
    return model
 
estimator = KerasClassifier(build_fn=baseline_model, epochs=3, batch_size=5, verbose=1)
kfold = KFold(n_splits=3, shuffle=True)
results = cross_val_score(estimator,total_features, labels, cv=kfold)
print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

import numpy as np
from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, random_state=0)

Image_2d = tsne.fit_transform(image_features)

Text_2d=tsne.fit_transform(text_features)

from matplotlib import pyplot as plt
plt.figure(figsize=(6, 5))
colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'w', 'orange', 'purple'
for i, c, label in zip(labels, colors, digits.target_names):
    plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1], c=c, label=label)
plt.legend()
plt.show()

from sklearn import datasets
digits = datasets.load_digits()
# Take the first 500 data points: it's hard to see 1500 points
X = total_features
y = labels_max

from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, random_state=0)

X_2d = tsne.fit_transform(X)

target_ids = range(len(digits.target_names))

from matplotlib import pyplot as plt
plt.figure(figsize=(6, 5))
colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'w', 'orange', 'purple'
for i, c, label in zip(target_ids, colors,digits.target_names):
  plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1], c=c, label=labels)
# plt.legend()

plt.title('t-sne plot of Text+Image Features')
plt.show()

print(digits.target_names)

labels_names=['Coffee Shop','Shop','Restaurent','Bank','Subway','Playfield','Theater','Bar','Hotel','Empty']

y = digits.target[:500]
print(X.shape,y.shape)

labels_max=np.zeros((560))
for i in range(560):
  labels_max[i]=np.argmax(labels[i,:])

np.unique(labels_max)

pickle_in = open("target.pkl","rb")

target = pickle.load(pickle_in)

import pickle

print(len(target))

pickle_in = open("textrecog_autocomplete.pkl","rb")
textrecog_autocomplete= pickle.load(pickle_in)

pickle_in = open("textrecog_chars2vec_embedding.pkl","rb")
textrecog_chars2vec_embedding= pickle.load(pickle_in)

print(len(textrecog_chars2vec_embedding))

pickle_in = open("textrecog_decoded.pkl","rb")
textrecog_decoded= pickle.load(pickle_in)

print(len(textrecog_decoded))

print(textrecog_decoded)

print(textrecog_chars2vec_embedding)

